[{"authors":null,"categories":null,"content":"I\u0026rsquo;m a PhD student in Machine Learning at University of Cambridge (Machine Learning Group, Computational and Biological Learning Lab) and Max Planck Institute for Intelligent Systems (Department of Empirical Inference), under the Cambridge-Tübingen PhD Fellowship. My supervisors are Prof. José Miguel Hernández-Lobato, Prof. Bernhard Schölkopf, and Dr. Hong Ge.\nI\u0026rsquo;m keen on basic research in machine learning and its scientific applications. My research interest lies at the intersection of deep learning and probabilistic methods. I\u0026rsquo;m exicted about developing efficient machine learning methods for robust prediction and realistic data generation.\n","date":1723334400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1723334400,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I\u0026rsquo;m a PhD student in Machine Learning at University of Cambridge (Machine Learning Group, Computational and Biological Learning Lab) and Max Planck Institute for Intelligent Systems (Department of Empirical Inference), under the Cambridge-Tübingen PhD Fellowship.","tags":null,"title":"Wenlin Chen","type":"authors"},{"authors":["Wen Wu","Wenlin Chen","Chao Zhang","Philip C. Woodland"],"categories":null,"content":"","date":1723334400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1723334400,"objectID":"3d127668f789f626cd8694802abe15f4","permalink":"https://wenlin-chen.github.io/publication/wu2024modelling/","publishdate":"2023-09-30T00:00:00Z","relpermalink":"/publication/wu2024modelling/","section":"publication","summary":"Human annotator simulation (HAS) serves as a cost-effective substitute for human evaluation tasks such as data annotation and system assessment. It is important to incorporate the variability present in human evaluation into HAS, since it helps capture diverse subjective interpretations and mitigate potential biases and over-representation. This work introduces a novel framework for modelling variability in HAS. Conditional softmax flow (S-CNF) is proposed to model the distribution of subjective human annotations, which leverages diverse human annotations via meta-learning. This enables the efficient generation of annotations that exhibit human variability for unlabelled input. In addition, a wide range of evaluation metrics are adopted to assess the capability and efficiency of HAS systems in predicting the aggregated behaviours of human annotators, matching the distribution of human annotations, and simulating the inter-annotator disagreements. Results demonstrate that the proposed method achieves state-of-the-art performance on two real-world human evaluation tasks: emotion recognition and toxic speech detection.","tags":[],"title":"Modelling Variability in Human Annotator Simulation","type":"publication"},{"authors":["Wenlin Chen","Mingtian Zhang","Brooks Paige","José Miguel Hernández-Lobato","David Barber"],"categories":null,"content":"","date":1721520000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1721520000,"objectID":"ce0f1bccc5bc8fef905bf5da977085b4","permalink":"https://wenlin-chen.github.io/publication/chen2024diffusive/","publishdate":"2024-02-04T00:00:00Z","relpermalink":"/publication/chen2024diffusive/","section":"publication","summary":"The inadequate mixing of conventional Markov Chain Monte Carlo (MCMC) methods for multi-modal distributions presents a significant challenge in practical applications such as Bayesian inference and molecular dynamics. Addressing this, we propose Diffusive Gibbs Sampling (DiGS), an innovative family of sampling methods designed for effective sampling from distributions characterized by distant and disconnected modes. DiGS integrates recent developments in diffusion models, leveraging Gaussian convolution to create an auxiliary noisy distribution that bridges isolated modes in the original space and applying Gibbs sampling to alternately draw samples from both spaces. A novel Metropolis-within-Gibbs scheme is proposed to enhance mixing in the denoising sampling step. DiGS exhibits a better mixing property for sampling multi-modal distributions than state-of-the-art methods such as parallel tempering, attaining substantially improved performance across various tasks, including mixtures of Gaussians, Bayesian neural networks and molecular dynamics. ","tags":[],"title":"Diffusive Gibbs Sampling","type":"publication"},{"authors":null,"categories":null,"content":"Generative Modeling Problem Setting Unknown data distribution $p_{data}(x)$. Samples from $p_{data}(x)$ are available. Goals Estimate the density of the data distributions $p_{data}(x)$. Generate new samples from $p_{data}(x)$. Diffusion Models and Score Matching Notation Denote data by $x_0=x$ and noise by $x_T$. Wiener process SDE ($dt\u0026gt;0$): $$dw_t=z\\sqrt{dt},\\quad z\\sim\\mathcal{N}(0,I).$$ Diffusion Process Forward diffusion SDE ($dt\u0026gt;0$): $$dx_t=f_t(x_t)dt+g_tdw_t.$$ Forward diffusion SDE corrupts data to noise. $f_t(x_t)$ is a vector-valued drift coefficient. $g_t$ is a scalar-valued diffusion coefficient. Reverse diffusion SDE ($dt\u0026lt;0$): $$dx_t=\\left(f_t(x_t)-g_t^2\\nabla_{x_t} \\log p_t(x_t)\\right)dt + g_tdw_t.$$ Reverse diffusion SDE recovers data from noise. Probability flow ODE ($dt\u0026lt;0$): $$dx_t=\\left(f_t(x_t)-\\frac{1}{2}g_t^2\\nabla_{x_t} \\log p_t(x_t)\\right)dt.$$ Probability flow ODE and reverse diffusion SDE have the same marginal $p_t(x_t)$ at every time $t$. Denoising Score Matching To generate data using the reverse diffusion SDE or probability flow PDE starting from a tractable noise distribution $\\pi(x_T)$, we need to estimate the score $\\nabla_{x_t} \\log p_t(x_t)$ at every time $t$. Learn a time-dependent score network $s_{\\theta}(x_t, t)$ by minimizing the score matching objetive: $$\\mathcal{L}_{SM}(\\theta) = \\mathbb{E}_{p_t(x_t)\\mathcal{U}(t|0,T)}[\\lambda(t)\\lVert s_{\\theta}(x_t, t) - \\nabla_{x_t} \\log p_t(x_t)\\rVert^2].$$ The score matching objective is intractable since we do not know the true score $\\nabla_{x_t} \\log p_t(x_t)$. We instead minimize the tractable denoising score matching objective: $$\\mathcal{L}_{DSM}(\\theta)=\\mathbb{E}_{p_{t|0}(x_t|x_0)p_{data}(x_0)\\mathcal{U}(t|0,T)}[\\lambda(t)\\lVert s_{\\theta}(x_t, t) - \\nabla_{x_t} \\log p_{t|0}(x_t|x_0)\\rVert^2].$$ It can be shown that $\\nabla_{\\theta}\\mathcal{L}_{SM}(\\theta)=\\nabla_{\\theta}\\mathcal{L}_{DSM}(\\theta).$ Proof: See my notes on Score Identities for Sampling and Generative Modeling. Weighting function $\\lambda(t)$: Magnitude weighting balances the magnitude of the score matching loss across time $t$: $$\\lambda(t)\\propto1/\\lVert \\nabla_{x_t} \\log p_{t|0}(x_t|x_0)\\rVert^2.$$ Likelihood weighting $\\lambda(t)=g_t^2$ leads to a nice connection between KL divergence and Fisher divergence: $$\\text{KL}(p_{data}(x_0)||p_{\\theta}(x_0))\\leq\\frac{T}{2}\\mathbb{E}_{p_t(x_t)\\mathcal{U}(t|0,T)}[g_t^2\\lVert s_{\\theta}(x_t, t) - \\nabla_{x_t} \\log p_t(x_t)\\rVert^2]+\\text{KL}(p_T(x_T)||\\pi(x_T)).$$ One problem with denoising score matching is that the score network $s_{\\theta}(x_t,t)$ is inaccurate for very small $t$ due to the large magnitude of $\\nabla_{x_t} \\log p_{t|0}(x_t|x_0)$. Continuous Normalizing Flows and Flow Matching Notation Denote data by $x_T=x$ and noise by $x_0$ This follows the convention in flow matching. Note: this is the opposite to the definition in diffusion models. Discrete Normalizing Flow Discrete normalzing flow with an invertible transformation function $\\phi$ (and $T=1$): $$x_1=\\phi(x_0),\\quad x_0\\sim\\pi(x_0),$$ $$\\log p(x_1)=\\log \\pi(\\phi^{-1}(x_1)) +\\log\\left|\\det\\frac{\\partial \\phi^{-1}(x_1)}{\\partial x_1}\\right|.$$ Compose $T$ discrete normalizing flows: $$x_{t+1}=\\phi_{t}(x_t),$$ $$\\phi=\\phi_{T-1}\\circ\\cdots\\circ\\phi_0,$$ $$\\log p(x_T)=\\log \\pi(\\phi^{-1}(x_T)) +\\sum_{t=1}^T\\log\\left|\\det\\frac{\\partial \\phi_{t-1}^{-1}(x_t)}{\\partial x_{t}}\\right|.$$ Discrete residual flow transformation: $$\\phi_t(x_t)=x_{t+1}=x_t+\\delta u_t(x_t).$$ $u_t$ needs to be $1/\\delta$-Lipschitz to guarantee the invertibility of $\\phi_t$. Learn a parametric flow transformation function $\\phi_{\\theta}$ by MLE: $$\\max_{\\theta}~\\mathbb{E}_{p_{data}(x_T)}[\\log p_{\\theta}(x_T)].$$ We need to enforce invertibility in the architecture of $\\phi_{\\theta}$. We need to compute and backpropagate through the inverse and Jacobian for $\\phi_{\\theta}$. Continuous Normalizing Flow Continuous residual flow transformation: $$x_{t+\\delta}=x_t+\\delta u_t(x_t).$$ $$u_t(x_t)=\\lim_{\\delta\\to0}\\frac{x_{t+\\delta}-x_t}{\\delta}=\\frac{dx_t}{dt}.$$ Continuous normalizing flow with a transformation function $\\phi_t$ induced by the vector field $u_t$: $$x_t=x_0+\\int_0^t u_s(x_s)ds,\\quad x_0\\sim\\pi(x_0),$$ Set $T=1$ following convention. The probability path $p_t$ induced by the vector field $u_t$ follows $$\\log p_t(x_t)=\\log\\pi(x_0)-\\int_{0}^t\\nabla_{x_s}\\cdot u_s(x_s)ds.$$ Proof: By the transport equation, we have $$ \\begin{aligned} \\frac{\\partial}{\\partial t} p_t(x_t) \u0026amp;= -\\nabla_{x_t}\\cdot(u_t(x_t)p_t(x_t)) \\\\ \u0026amp;= -p_t(x_t)\\nabla_{x_t}\\cdot u_t(x_t)-\\left\u0026lt;\\nabla_{x_t}p_t(x_t),u_t(x_t)\\right\u0026gt;. \\end{aligned}$$ The total derivative is then given by $$ \\begin{aligned} \\frac{d}{d t} p_t(x_t) \u0026amp;= \\frac{\\partial}{\\partial t} p_t(x_t) + \\left\u0026lt;\\nabla_{x_t}p_t(x_t),\\frac{dx_t}{d t}\\right\u0026gt; \\\\ \u0026amp;= -p_t(x_t)\\nabla_{x_t}\\cdot u_t(x_t)-\\left\u0026lt;\\nabla_{x_t}p_t(x_t),u_t(x_t)\\right\u0026gt; + \\left\u0026lt;\\nabla_{x_t}p_t(x_t),u_t(x_t)\\right\u0026gt; \\\\ \u0026amp;= -p_t(x_t)\\nabla_{x_t}\\cdot u_t(x_t). \\end{aligned} $$ Therefore, we have $$\\frac{d}{dt}\\log p_t(x_t)=\\frac{1}{p_t(x_t)}\\frac{d}{d t} p_t(x_t)=-\\nabla_{x_t}\\cdot u_t(x_t).$$ In practice, both $x_t$ and $\\log p_t(x_t)$ can be solved jointly using a numerical ODE integrator: $$ \\frac{d}{dt} \\begin{pmatrix} x_t \\\\ \\log p_t(x_t) \\end{pmatrix}= \\begin{pmatrix} u_t(x_t) \\\\ -\\nabla_{x_t}\\cdot u_t(x_t) \\end{pmatrix}. $$ Note that there are many different vector fields $u_t$ that can induce probability paths between $p_0$ and $p_1$. Learn a parameteric time-dependent vector field $u_{\\theta}(x_t, t)$ by MLE: $$\\max_{\\theta}~\\mathbb{E}_{p_{data}(x_1)}[\\log p_{\\theta}(x_1)].$$ We do not need to choose the number of flow transformations as in composed discrete normalizing flows. $u_t$ only needs to be $L$-Lipschitz with any value $L$ to guarantee the invertibility of $\\phi_t$. Numerical simulation of the ODE with backpropagation makes training very slow and expensive. Divergence estimator scales poorly with dimensionality. Conditional Flow Matching We want a simulation-free objective like score matching. Learn a time-dependent vector field $u_{\\theta}(x_t, t)$ by minimizing the flow matching objetive: $$\\mathcal{L}_{FM}(\\theta)=\\mathbb{E}_{p_t(x_t)\\mathcal{U}(t|0,1)}[\\lVert u_{\\theta}(x_t, t)-u_t(x_t)\\rVert^2].$$ The flow matching objective is intractable since we do not know the true vector field $u_t(x_t)$. To circumvent the intractability, we consider a specific probability path $p_t(x_t)$ defined by a conditional probability path $p_{t|1}(x_t|x_1)$: $$p_t(x_t)=\\int p_{t|1}(x_t|x_1)p_{data}(x_1)dx_1,$$ with boundary conditions $$p_{0|1}(x)=\\pi(x)\\implies p_0(x_0)=\\pi(x_0),$$ $$p_{1|1}(x)=\\delta(x-x_1)\\implies p_1(x_1)=p_{data}(x_1).$$ The marginal vector field $u_t$ can be obtained from the corresponding conditional vector field $u_{t|1}(x_t|x_1)$ and conditional probability path $p_{t|1}(x_t|x_1)$ through the following identity: $$u_t(x_t)=\\mathbb{E}_{p_{1|t}(x_1|x_t)}[u_{t|1}(x_t|x_1)]=\\int u_{t|1}(x_t|x_1)\\frac{p_{t|1}(x_t|x_1)p_{data}(x_1)}{p_t(x_t)}dx_1.$$ Proof: We verify that this is consistent with the transport equation for the marginals. $$ \\begin{aligned} \\frac{\\partial}{\\partial t}p_t(x_t) \u0026amp;= \\frac{\\partial}{\\partial t} \\int p_{t|1}(x_t|x_1)p_{data}(x_1)dx_1 \\\\ \u0026amp;= \\int \\frac{\\partial}{\\partial t} p_{t|1}(x_t|x_1)p_{data}(x_1)dx_1 \\\\ \u0026amp;= - \\int \\nabla_{x_t}\\cdot (u_{t|1}(x_t|x_1)p_{t|1}(x_t|x_1)) p_{data}(x_1)dx_1 \\\\ \u0026amp;= - \\int \\nabla_{x_t}\\cdot (u_{t|1}(x_t|x_1)p_{t|1}(x_t|x_1)p_{data}(x_1)) dx_1 \\\\ \u0026amp;= - \\nabla_{x_t}\\cdot \\int u_{t|1}(x_t|x_1)p_{t|1}(x_t|x_1)p_{data}(x_1) dx_1 \\\\ \u0026amp;= - \\nabla_{x_t}\\cdot \\left( \\int u_{t|1}(x_t|x_1)\\frac{p_{t|1}(x_t|x_1)p_{data}(x_1)}{p_t(x_t)} dx_1 p_t(x_t) \\right) \\\\ \u0026amp;= - \\nabla_{x_t}\\cdot (u_t(x_t) p_t(x_t)). \\\\ \\end{aligned} $$ We now introduce a tractable conditional flow matching objective: $$\\mathcal{L}_{CFM}(\\theta)=\\mathbb{E}_{p_{t|1}(x_t|x_1)p_{data}(x_1)\\mathcal{U}(t|0,1)}[\\lVert u_{\\theta}(x_t,t)-u_{t|1}(x_t|x_1) \\rVert^2].$$ It can be shown that $\\nabla_{\\theta}\\mathcal{L}_{FM}(\\theta)=\\nabla_{\\theta}\\mathcal{L}_{CFM}(\\theta)$. Proof: We follow a similar idea to the proof of denoising score matching but with the following equality. $$ \\begin{aligned} \\mathbb{E}_{p_t(x_t)}[\\left\u0026lt;u_{\\theta}(x_t,t),u_t(x_t)\\right\u0026gt;] \u0026amp;= \\int \\left\u0026lt;u_{\\theta}(x_t,t),u_t(x_t)\\right\u0026gt; p_t(x_t) dx_t \\\\ \u0026amp;= \\int \\left\u0026lt;u_{\\theta}(x_t,t),\\int u_{t|1}(x_t|x_1)\\frac{p_{t|1}(x_t|x_1)p_{data}(x_1)}{p_t(x_t)}dx_1\\right\u0026gt; p_t(x_t) dx_t \\\\ \u0026amp;= \\iint \\left\u0026lt;u_{\\theta}(x_t,t),u_{t|1}(x_t|x_1)\\right\u0026gt; p_{t|1}(x_t|x_1)p_{data}(x_1)dx_1 dx_t \\\\ \u0026amp;= \\mathbb{E}_{p_{t|1}(x_t|x_1)p_{data}(x_1)}[\\left\u0026lt;u_{\\theta}(x_t,t),u_{t|1}(x_t|x_1)\\right\u0026gt;]. \\end{aligned} $$ In practice, we may want our conditional vector field $u_{t|1}$ to generate a conditional Gaussian probability path: $$p_{t|1}(x_t|x_1)=\\mathcal{N}(x_t|\\mu_t(x_1),\\sigma_t(x_1)^2I),$$ with boundary conditions $$\\mu_0(x_1)=0,\\quad\\sigma_0(x_1)=1,$$ $$\\mu_1(x_1)=x_1,\\quad\\sigma_1(x_1)=0.$$ One correpsonding conditional vector field is given by $$u_{t|1}(x_t|x_1)=\\frac{x-\\mu_t(x_1)}{\\sigma_t(x_1)}\\frac{d\\sigma_t(x_1)}{d t}+\\frac{d \\mu_t(x_1)}{d t},$$ with a conditional flow transformation $$\\phi_{t|1}(x_0|x_1)=\\mu_t(x_1)+\\sigma_t(x_1)x_0.$$ Proof: We prove it by verifying the following two quantities are identical. $$\\frac{d}{dt}\\phi_{t|1}(x_0|x_1)=\\frac{d}{dt}\\mu_t(x_1)+x_0\\frac{d}{dt}\\sigma_t(x_1),$$ and $$ \\begin{aligned} u_{t|1}(\\phi_{t|1}(x_0|x_1)|x_1) \u0026amp;= \\frac{\\mu_t(x_1)+\\sigma_t(x_1)x_0-\\mu_t(x_1)}{\\sigma_t(x_1)}\\frac{d\\sigma_t(x_1)}{d t}+\\frac{d \\mu_t(x_1)}{d t} \\\\ \u0026amp;=x_0\\frac{d}{dt}\\sigma_t(x_1)+\\frac{d}{dt}\\mu_t(x_1). \\end{aligned} $$ Two problems with conditional flow matching: The estimate of the gradient $\\nabla_{\\theta} \\mathcal{L}_{CFM}(\\theta)$ is of high variance since there are many possible data $x_1$ corresponding to a noise $x_0$ due to intersection of probability paths for different realizations of $u_{t|1}(x_t|x_1)$ with different values of the conditioning variable $x_1$. Sampling is slow at generation time since it is difficult to integrate ODE with non-straight marginal path $u_{\\theta}(u_t,t)$. Coupling: instead of maping between data $x_1$ and noise $x_0$ (i.e., one-sided conditioning), we can similarly map between any two variables $x_0$ and $x_1$ with two-sided conditioning: $$p_t(x_t)=\\iint p_{t|0,1}(x_t|x_0,x_1)p_{data}(x_0,x_1)dx_0dx_1,$$ with boundary conditions $$p_{0|0,1}(x|x_0,x_1)=\\delta(x-x_0)\\implies p_0(x_0)=p_{data}(x_0),$$ $$p_{1|0,1}(x|x_0,x_1)=\\delta(x-x_1)\\implies p_1(x_1)=p_{data}(x_1).$$ ","date":1717891200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717891200,"objectID":"30118056e04e4a5a9f78efaf23f0c8fa","permalink":"https://wenlin-chen.github.io/post/gen/","publishdate":"2024-06-09T00:00:00Z","relpermalink":"/post/gen/","section":"post","summary":"Generative Modeling Problem Setting Unknown data distribution $p_{data}(x)$. Samples from $p_{data}(x)$ are available. Goals Estimate the density of the data distributions $p_{data}(x)$. Generate new samples from $p_{data}(x)$. Diffusion Models and Score Matching Notation Denote data by $x_0=x$ and noise by $x_T$.","tags":null,"title":"Score Matching and Flow Matching","type":"post"},{"authors":null,"categories":null,"content":"Introduction Problem Setting Data distribution: $$p(x)=\\frac{\\exp(-E(x))}{Z}.$$ Intractable normalizing constant: $$Z=\\int \\exp(-E(x)) dx.$$ Tractable score function: $$\\nabla_x \\log p(x)=-\\nabla_x E(x).$$ Generative Modeling: Samples from $p(x)$ are available. The energy function $E$ is unknown and needs to be learned from data. Sampling: The energy function $E$ is given. Samples from $p(x)$ are not available. Diffusion Gaussian convolution kernel: $$p(y|x)=\\mathcal{N}(y|\\alpha x,\\sigma^2 I).$$ Intractable noisy marginal: $$p(y)=\\int p(y|x)p(x)dx.$$ Intractable denoising posterior: $$p(x|y)=\\frac{p(y|x)p(x)}{p(y)}.$$ Intractable noisy score: $$\\nabla_y\\log p(y)=\\nabla_y\\log \\int p(y|x)p(x)dx.$$ Score Identities Denoising Score Identity Denoising score identity is a general formula without assumping the form of $p(y|x)$: $$\\nabla_y\\log p(y)=\\mathbb{E}_{p(x|y)}[\\nabla_y\\log p(y|x)]=\\int\\nabla_y\\log p(y|x) p(x|y)dx.$$ Proof: By definition, we have $$ \\begin{aligned} \\nabla_y\\log p(y) \u0026amp;= \\frac{\\int\\nabla_y p(y|x)p(x)dx}{p(y)} \\\\ \u0026amp;= \\int\\nabla_y\\log(y|x)\\frac{p(y|x)p(x)}{p(y)}dx \\\\ \u0026amp;= \\int\\nabla_y\\log p(y|x) p(x|y)dx. \\end{aligned} $$ Tweedie Score Identity Tweedie score identity assumes Gaussian convolution $p(y|x)=\\mathcal{N}(y|\\alpha x,\\sigma^2 I)$: $$\\nabla_y\\log p(y)=\\frac{\\alpha\\mathbb{E}_{p(x|y)}[ x ]-y}{\\sigma^2}=\\int\\left(\\frac{\\alpha x-y}{\\sigma^2}\\right)p(x|y)dx.$$ Proof: By denoising score identity, we have $$ \\begin{aligned} \\nabla_y\\log p(y) \u0026amp;= \\int\\nabla_y\\log p(y|x) p(x|y)dx \\\\ \u0026amp;= \\int\\nabla_y\\left(-\\frac{\\lVert y-\\alpha x\\rVert^2}{2\\sigma^2}\\right) p(x|y)dx \\\\ \u0026amp;= \\int \\left(\\frac{\\alpha x-y}{\\sigma^2}\\right)p(x|y)dx. \\end{aligned} $$ Target Score Identity Target score identity assumes Gaussian convolution $p(y|x)=\\mathcal{N}(y|\\alpha x,\\sigma^2 I)$: $$\\nabla_y\\log p(y)=\\alpha^{-1}\\mathbb{E}_{p(x|y)}[\\nabla_x\\log p(x)]=\\alpha^{-1}\\int \\nabla_x\\log p(x) p(x|y) dx.$$ Proof: By denoising score identity and using the following three identities $$\\nabla_y \\log p(y|x)=-\\alpha^{-1}\\nabla_x \\log p(y|x),$$ $$\\nabla_x \\log p(y|x)=\\nabla_x\\log p(x|y)-\\nabla_x \\log p(x),$$ $$\\int \\nabla_x\\log p(x|y)p(x|y)dx=\\int \\nabla_xp(x|y)dx=\\nabla_x\\int p(x|y)dx=0,$$ we have $$ \\begin{aligned} \\nabla_y\\log p(y) \u0026amp;= \\int\\nabla_y\\log p(y|x) p(x|y)dx \\\\ \u0026amp;= -\\alpha^{-1}\\int\\nabla_x\\log p(y|x) p(x|y)dx \\\\ \u0026amp;= \\alpha^{-1}\\int(\\nabla_x \\log p(x)-\\nabla_x\\log p(x|y)) p(x|y)dx \\\\ \u0026amp;= \\alpha^{-1}\\int\\nabla_x \\log p(x) p(x|y)dx. \\end{aligned} $$ Mixed Score Identity Mixed score identity assumes Gaussian convolution $p(y|x)=\\mathcal{N}(y|\\alpha x,\\sigma^2 I)$ with a variance-preserving scheme $\\sigma^2=1-\\alpha^2$: $$\\nabla_y\\log p(y)=\\mathbb{E}_{p(x|y)}[\\alpha(x+\\nabla_x\\log p(x))-y]=\\int (\\alpha(x+\\nabla_x\\log p(x))-y) p(x|y) dx.$$ Proof: Consider a convex combination of the target score identity and Tweedie score identity with coefficients $\\alpha^2$ and $1-\\alpha^2$: $$ \\begin{aligned} \\nabla_y\\log p(y) \u0026amp;= \\int \\left((\\alpha^2\\frac{\\nabla_x \\log p(x)}{\\alpha} + (1-\\alpha^2)\\frac{\\alpha x - y}{\\sigma^2}\\right)p(x|y)dx \\\\ \u0026amp;= \\int (\\alpha(x+\\nabla_x\\log p(x))-y) p(x|y) dx. \\end{aligned} $$ Score-based Sampling Monte Carlo Estimator Estimate the noisy score with Tweedie score identity using Monte Carlo: $$\\nabla_y \\log p(y)\\approx \\frac{\\frac{\\alpha}{K}\\sum_{k=1}^K x_k-y}{\\sigma^2},\\quad x_k\\sim p(x|y).$$ We may initialize the sampler for $p(x|y)$ with its mean $\\mathbb{E}_{p(x|y)}[ x ]$ estimated by importance sampling: $$\\mathbb{E}_{p(x|y)}[ x ]\\approx\\frac{\\sum_{l=1}^L x_l\\exp(-E(x_l))}{\\sum_{l=1}^L \\exp(-E(x_{l}))},\\quad x_l\\sim q(x|y)=\\mathcal{N}\\left(x\\left|\\frac{y}{\\alpha},\\left(\\frac{\\sigma}{\\alpha}\\right)^2I\\right)\\right..$$ This is the standard importance sampling approach. It does not work well in high dimensional space. Proof: Using the fact that $q(x|y)\\propto p(y|x)$, we have $$ \\begin{aligned} \\mathbb{E}_{p(x|y)}[ x ] \u0026amp;= \\int x p(x|y)dx \\\\ \u0026amp;= \\int x \\frac{p(y|x)p(x)}{p(y)}dx \\\\ \u0026amp;= \\frac{\\int x p(y|x)p(x)dx}{\\int p(y|x)p(x)dx} \\\\ \u0026amp;= \\frac{\\int x \\exp(-E(x))q(x|y)dx}{\\int \\exp(-E(x))q(x|y)dx} \\\\ \u0026amp;\\approx \\frac{\\sum_{l=1}^L x_l\\exp(-E(x_l))}{\\sum_{l=1}^L \\exp(-E(x_{l}))},\\quad x_l\\sim q(x|y). \\end{aligned} $$ Importance Sampling Estimator Estimate the noisy score with the target score identity using importance sampling: $$\\nabla_y \\log p(y)\\approx -\\frac{\\sum_{k=1}^K \\exp(-E(x_k))\\nabla_x E(x_k)}{\\alpha\\sum_{k=1}^K \\exp(-E(x_k))},\\quad x_k\\sim q(x|y)=\\mathcal{N}\\left(x\\left|\\frac{y}{\\alpha},\\left(\\frac{\\sigma}{\\alpha}\\right)^2I\\right)\\right..$$ This does not work well in practice as it only works for very small $t$. Proof: Using target score identity and the fact that $q(x|y)\\propto p(y|x)$, we have $$ \\begin{aligned} \\nabla_y\\log p(y) \u0026amp;= \\alpha^{-1}\\int \\nabla_x\\log p(x) p(x|y) dx \\\\ \u0026amp;= \\frac{\\int \\nabla_x\\log p(x) p(y|x)p(x) dx}{\\alpha p(y)} \\\\ \u0026amp;= \\frac{\\int \\nabla_x\\log p(x) p(y|x)p(x) dx}{\\alpha \\int p(y|x)p(x)dx} \\\\ \u0026amp;= \\frac{\\int \\nabla_x\\log p(x) \\exp(-E(x)) q(x|y) dx}{\\alpha \\int \\exp(-E(x)) q(x|y)dx} \\\\ \u0026amp;\\approx -\\frac{\\sum_{k=1}^K \\exp(-E(x_k))\\nabla_x E(x_k)}{\\alpha\\sum_{k=1}^K \\exp(-E(x_k))},\\quad x_k\\sim q(x|y). \\end{aligned} $$ Score-based Generative Modeling Denoising Score Matching Learn a noisy score network $s_{\\theta}(y)$ by minimizing $$ \\begin{aligned} \\mathcal{L}(\\theta) \u0026amp;= \\mathbb{E}_{p(y)}[\\lVert s_{\\theta}(y) - \\nabla_y \\log p(y)\\rVert^2] \\\\ \u0026amp;= \\mathbb{E}_{p(y|x)p(x)}[\\lVert s_{\\theta}(y) - \\nabla_y \\log p(y|x)\\rVert^2]+C. \\end{aligned} $$ This is the most popular generative modeling apporach. It is inaccurate for very small $t$. Proof: Using the denoising score identity, we have $$ \\begin{aligned} \\mathbb{E}_{p(y)}[\\lVert s_{\\theta}(y) - \\nabla_y \\log p(y)\\rVert^2] \u0026amp;= \\int \\lVert s_{\\theta}(y) - \\nabla_y \\log p(y)\\rVert^2 p(y) dy \\\\ \u0026amp;= \\int \\lVert s_{\\theta}(y) \\rVert^2 p(y) dy - 2 \\int \\left\u0026lt;s_{\\theta}(y),\\nabla_y \\log p(y)\\right\u0026gt;p(y)dy + C\u0026rsquo; \\\\ \u0026amp;= \\int \\lVert s_{\\theta}(y) \\rVert^2 p(y) dy - 2 \\iint \\left\u0026lt;s_{\\theta}(y),\\nabla_y\\log p(y|x) \\right\u0026gt;p(x|y)p(y)dxdy + C\u0026rsquo; \\\\ \u0026amp;= \\int \\lVert s_{\\theta}(y) \\rVert^2 p(y) dy - 2 \\iint \\left\u0026lt;s_{\\theta}(y),\\nabla_y\\log p(y|x) \\right\u0026gt;p(y|x)p(x)dxdy + C\u0026rsquo; \\\\ \u0026amp;= \\iint \\left( \\lVert s_{\\theta}(y) \\rVert^2 + \\lVert \\nabla_y\\log p(y|x) \\rVert^2 - 2 \\left\u0026lt;s_{\\theta}(y),\\nabla_y\\log p(y|x) \\right\u0026gt;\\right)p(y|x)p(x)dxdy + C \\\\ \u0026amp;= \\iint \\lVert s_{\\theta}(y) - \\nabla_y \\log p(y|x)\\rVert^2 p(y|x)p(x)dxdy + C \\\\ \u0026amp;= \\mathbb{E}_{p(y|x)p(x)}[\\lVert s_{\\theta}(y) - \\nabla_y \\log p(y|x)\\rVert^2]+C. \\end{aligned} $$ Nonparametric Estimator Estimate the noisy score with the target score identity using with a KDE-style estimator: $$\\nabla_y \\log p(y)\\approx\\frac{\\sum_{k=1}^K p(y|x_k)\\nabla_y \\log p(y|x_k)}{\\sum_{k=1}^K p(y|x_k)},\\quad x_k\\sim p(x).$$ This is expensive to evaluate and needs to be recomputed for different $y$. Proof: By definition of noisy score, we have $$ \\begin{aligned} \\nabla_y\\log p(y) \u0026amp;= \\nabla_y\\log \\int p(y|x)p(x)dx \\\\ \u0026amp;\\approx \\nabla_y\\log\\sum_{k=1}^K p(y|x_k),\\quad x_k\\sim p(x) \\\\ \u0026amp;= \\frac{\\sum_{k=1}^K \\nabla_y p(y|x_k)}{\\sum_{k=1}^K p(y|x_k)},\\quad x_k\\sim p(x) \\\\ \u0026amp;= \\frac{\\sum_{k=1}^K p(y|x_k)\\nabla_y \\log p(y|x_k)}{\\sum_{k=1}^K p(y|x_k)},\\quad x_k\\sim p(x). \\end{aligned} $$ ","date":1717200000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717200000,"objectID":"19a6bc66ab7d6c59a41b7d57746d5859","permalink":"https://wenlin-chen.github.io/post/score/","publishdate":"2024-06-01T00:00:00Z","relpermalink":"/post/score/","section":"post","summary":"Introduction Problem Setting Data distribution: $$p(x)=\\frac{\\exp(-E(x))}{Z}.$$ Intractable normalizing constant: $$Z=\\int \\exp(-E(x)) dx.$$ Tractable score function: $$\\nabla_x \\log p(x)=-\\nabla_x E(x).$$ Generative Modeling: Samples from $p(x)$ are available. The energy function $E$ is unknown and needs to be learned from data.","tags":null,"title":"Score Identities for Sampling and Generative Modeling","type":"post"},{"authors":["Wen Wu","Wenlin Chen","Chao Zhang","Philip C. Woodland"],"categories":null,"content":"","date":1696032000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696032000,"objectID":"a813e18c87043788c6c22b08f0d565dd","permalink":"https://wenlin-chen.github.io/publication/wu2023has/","publishdate":"2023-09-30T00:00:00Z","relpermalink":"/publication/wu2023has/","section":"publication","summary":"Human annotator simulation (HAS) serves as a cost-effective substitute for human evaluation such as data annotation and system assessment. Human perception and behaviour during human evaluation exhibit inherent variability due to diverse cognitive processes and subjective interpretations, which should be taken into account in modelling to better mimic the way people perceive and interact with the world. This paper introduces a novel meta-learning framework that treats HAS as a zero-shot density estimation problem, which incorporates human variability and allows for the efficient generation of human-like annotations for unlabelled test inputs. Under this framework, we propose two new model classes, conditional integer flows and conditional softmax flows, to account for ordinal and categorical annotations, respectively. The proposed method is evaluated on three real-world human evaluation tasks and shows superior capability and efficiency to predict the aggregated behaviours of human annotators, match the distribution of human annotations, and simulate the inter-annotator disagreements.","tags":[],"title":"It HAS to be Subjective: Human Annotator Simulation via Zero-shot Density Estimation","type":"publication"},{"authors":["Wenlin Chen","Julien Horwood","Juyeon Heo","José Miguel Hernández-Lobato"],"categories":null,"content":"","date":1687824000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1687824000,"objectID":"6039f5f4bbc26f58c353b25a8afbb2f9","permalink":"https://wenlin-chen.github.io/publication/chen2023leveraging/","publishdate":"2023-06-27T00:00:00Z","relpermalink":"/publication/chen2023leveraging/","section":"publication","summary":"This work extends the theory of identifiability in supervised learning by considering the consequences of having access to a distribution of tasks. In such cases, we show that identifiability is achievable even in the case of regression, extending prior work restricted to the single-task classification case. Furthermore, we show that the existence of a task distribution which defines a conditional prior over latent variables reduces the equivalence class for identifiability to permutations and scaling, a much stronger and more useful result. When we further assume a causal structure over these tasks, our approach enables simple maximum marginal likelihood optimization together with downstream applicability to causal representation learning. Empirically, we validate that our model outperforms more general unsupervised models in recovering canonical representations for synthetic and real-world data.","tags":[],"title":"Leveraging Task Structures for Improved Identifiability in Neural Network Representations","type":"publication"},{"authors":["Wenlin Chen","Hong Ge"],"categories":null,"content":"","date":1684972800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684972800,"objectID":"bb7541be91c73c5a7ef7f163ee4ce10e","permalink":"https://wenlin-chen.github.io/publication/chen2023relu/","publishdate":"2023-05-25T00:00:00Z","relpermalink":"/publication/chen2023relu/","section":"publication","summary":"We introduce a novel approach for analyzing the training dynamics of ReLU networks by examining the characteristic activation boundaries of individual ReLU neurons. Our proposed analysis reveals a critical instability in common neural network parameterizations and normalizations during stochastic optimization, which impedes fast convergence and hurts generalization performance. Addressing this, we propose Geometric Parameterization (GmP), a novel neural network parameterization technique that effectively separates the radial and angular components of weights in the hyperspherical coordinate system. We show theoretically that GmP resolves the aforementioned instability issue. We report empirical results on various models and benchmarks to verify GmP's theoretical advantages of optimization stability, convergence speed and generalization performance.","tags":[],"title":"ReLU Characteristic Activation Analysis","type":"publication"},{"authors":["Wenlin Chen","Austin Tripp","José Miguel Hernández-Lobato"],"categories":null,"content":"","date":1682899200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682899200,"objectID":"e7e2dce54685980967029d324635a717","permalink":"https://wenlin-chen.github.io/publication/chen2023meta/","publishdate":"2022-05-05T00:00:00Z","relpermalink":"/publication/chen2023meta/","section":"publication","summary":"We propose Adaptive Deep Kernel Fitting with Implicit Function Theorem (ADKF-IFT), a novel framework for learning deep kernel Gaussian processes (GPs) by interpolating between meta-learning and conventional deep kernel learning. Our approach employs a bilevel optimization objective where we meta-learn generally useful feature representations across tasks, in the sense that task-specific GP models estimated on top of such features achieve the lowest possible predictive loss on average. We solve the resulting nested optimization problem using the implicit function theorem (IFT). We show that our ADKF-IFT framework contains previously proposed Deep Kernel Learning (DKL) and Deep Kernel Transfer (DKT) as special cases. Although ADKF-IFT is a completely general method, we argue that it is especially well-suited for drug discovery problems and demonstrate that it significantly outperforms previous state-of-the-art methods on a variety of real-world few-shot molecular property prediction tasks and out-of-domain molecular property prediction and optimization tasks.","tags":[],"title":"Meta-learning Adaptive Deep Kernel Gaussian Processes for Molecular Property Prediction","type":"publication"},{"authors":["Wenlin Chen","Samuel Horváth","Peter Richtárik"],"categories":null,"content":"","date":1661126400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661126400,"objectID":"eee04c746fd5fbd08cbed0a0667cb0ed","permalink":"https://wenlin-chen.github.io/publication/chen2022optimal/","publishdate":"2022-08-04T00:00:00Z","relpermalink":"/publication/chen2022optimal/","section":"publication","summary":"It is well understood that client-master communication can be a primary bottleneck in federated learning (FL). In this work, we address this issue with a novel client subsampling scheme, where we restrict the number of clients allowed to communicate their updates back to the master node. In each communication round, all participating clients compute their updates, but only the ones with \"important\" updates communicate back to the master. We show that importance can be measured using only the norm of the update and give a formula for optimal client participation. This formula minimizes the distance between the full update, where all clients participate, and our limited update, where the number of participating clients is restricted. In addition, we provide a simple algorithm that approximates the optimal formula for client participation, which allows for secure aggregation and stateless clients, and thus does not compromise client privacy. We show both theoretically and empirically that for Distributed SGD (DSGD) and Federated Averaging (FedAvg), the performance of our approach can be close to full participation and superior to the baseline where participating clients are sampled uniformly. Moreover, our approach is orthogonal to and compatible with existing methods for reducing communication overhead, such as local methods and communication compression methods.","tags":[],"title":"Optimal Client Sampling for Federated Learning","type":"publication"},{"authors":["Austin Tripp","Wenlin Chen","José Miguel Hernández-Lobato"],"categories":null,"content":"","date":1651190400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651190400,"objectID":"7c674ec1dda2935eabce28cc88b5af57","permalink":"https://wenlin-chen.github.io/publication/tripp2022evaluation/","publishdate":"2022-04-29T00:00:00Z","relpermalink":"/publication/tripp2022evaluation/","section":"publication","summary":"De novo drug design has recently received increasing attention from the machine learning community. It is important that the field is aware of the actual goals and challenges of drug design and the roles that de novo molecule design algorithms could play in accelerating the process, so that algorithms can be evaluated in a way that reflects how they would be applied in real drug design scenarios. In this paper, we propose a framework for critically assessing the merits of benchmarks, and argue that most of the existing de novo drug design benchmark functions are either highly unrealistic or depend upon a surrogate model whose performance is not well characterized. In order for the field to achieve its long-term goals, we recommend that poor benchmarks (especially logP and QED) be deprecated in favour of better benchmarks. We hope that our proposed framework can play a part in developing new de novo drug design benchmarks that are more realistic and ideally incorporate the intrinsic goals of drug design.","tags":[],"title":"An Evaluation Framework for the Objective Functions of De Novo Drug Design Benchmarks","type":"publication"},{"authors":["Wenlin Chen"],"categories":null,"content":"","date":1629331200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629331200,"objectID":"12bedca3d469d735925baf247e9638c5","permalink":"https://wenlin-chen.github.io/publication/chen2021causal/","publishdate":"2021-08-19T00:00:00Z","relpermalink":"/publication/chen2021causal/","section":"publication","summary":"In this thesis, we study causal representation learning for latent space optimization, which allows for robust and efficient generation of novel synthetic data with maximal target value.  We assume that the observed data was generated by a few latent factors, some of which are causally related to the target and others of which are spuriously correlated with the target and confounded by an environment variable. Our proposed method consists of three steps, which exploits the structure of the causal graph that describes the assumed underlying data generating process. In the first step, we recover the true data representation (i.e., the latent factors from which the observed data originated). We obtain novel identifiability theory, showing that the true data representation can be recovered up to simple transformations by a generalized version of identifiable variational auto-encoders. In the second step, we identify the causal latent factors of the target, for which we propose a practical causal inference scheme that employs (conditional) independence tests and causal discovery algorithms. Our method does not require having access to the true environment variable, which overcomes a major limitation of existing causal representation learning approaches in the literature. In the final step, we query latent points that correspond to data points with high target values by intervening upon the causal latent factors using standard latent space optimization techniques. We empirically evaluate and thoroughly analyze our method on three different tasks, including a chemical design task. We show that our method can successfully recover the true data representation in the finite data regime and correctly identify the causal latent factors of the target, which results in state-of-the-art performance for black-box optimization.","tags":[],"title":"Causal Representation Learning for Latent Space Optimization","type":"publication"},{"authors":["Andrew Webb","Charles Reynolds","Wenlin Chen","Henry Reeve","Dan Iliescu","Mikel Luján","Gavin Brown"],"categories":null,"content":"","date":1600041600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600041600,"objectID":"73540bab56f2b0d108a710976f7b0dcb","permalink":"https://wenlin-chen.github.io/publication/webb2020ensemble/","publishdate":"2020-09-14T00:00:00Z","relpermalink":"/publication/webb2020ensemble/","section":"publication","summary":"End-to-End training (E2E) is becoming more and more popular to train complex Deep Network architectures. An interesting question is whether this trend will continue—are there any clear failure cases for E2E training? We study this question in depth, for the specific case of E2E training an ensemble of networks. Our strategy is to blend the gradient smoothly in between two extremes: from independent training of the networks, up to to full E2E training. We find clear failure cases, where overparameterized models cannot be trained E2E. A surprising result is that the optimum can sometimes lie in between the two, neither an ensemble or an E2E system. The work also uncovers links to Dropout, and raises questions around the nature of ensemble diversity and multi-branch networks.","tags":[],"title":"To Ensemble or Not Ensemble: When Does End-to-End Training Fail?","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://wenlin-chen.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]