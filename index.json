[{"authors":null,"categories":null,"content":"I am a PhD student in Machine Learning at University of Cambridge (Machine Learning Group, Computational and Biological Learning Lab) and Max Planck Institute for Intelligent Systems (Department of Empirical Inference), under the Cambridge-Tübingen PhD Fellowship in Machine Learning. My supervisors are Professor José Miguel Hernández-Lobato, Professor Bernhard Schölkopf, and Dr Hong Ge.\nI am keen on basic research in machine learning and its scientific applications. My research interest lies at the intersection of probabilistic methods, deep learning, and causal inference. I aim to develop efficient machine learning methods for robust prediction and realistic data generation.\n","date":1696032000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1696032000,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a PhD student in Machine Learning at University of Cambridge (Machine Learning Group, Computational and Biological Learning Lab) and Max Planck Institute for Intelligent Systems (Department of Empirical Inference), under the Cambridge-Tübingen PhD Fellowship in Machine Learning.","tags":null,"title":"Wenlin Chen","type":"authors"},{"authors":null,"categories":null,"content":"Introduction Let $p(\\mathbf{x}_0)$ be the data distribution of interest. Consider a Gaussian forward diffusion process in the following form: $$ p(\\mathbf{x}_t|\\mathbf{x}_0)=\\mathcal{N}(\\mathbf{x}_t|\\gamma_t \\mathbf{x}_0,\\sigma_t^2\\mathbf{I}), $$ or, equivalently, $$ \\mathbf{x}_t=\\gamma_t \\mathbf{x}_0 + \\sigma_t\\mathbf{z},\\quad\\mathbf{z}\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I}). $$\nThe marginal distribution of the noisy data $\\mathbf{x}_t$ can be expressed as $$ p(\\mathbf{x}_t)=\\int p(\\mathbf{x}_t|\\mathbf{x}_0)p(\\mathbf{x}_0)d\\mathbf{x}_0. $$\nCommon Parameterizations of Diffusion Generative Models Diffusion generative models aim to learn the corresponding backward diffusion process (i.e., the denoising process) which can be used to generate data from noise. Two of the most common parameterizations of diffusion generative models are:\nDenoising Diffusion Probabilistic Model (DDPM) predicts the mean $\\mathbb{E}[\\mathbf{x}_{t-1}|\\mathbf{x}_t]$ of each step in the backward process. Applying certain variance reduction tricks reduces this to predicting the noise $\\mathbf{z}$ that was used to generate $\\mathbf{x}_t$ with a noise model $\\mathbf{z}_{\\boldsymbol{\\theta}}(\\mathbf{x}_t,t)$: $$ \\min_{\\boldsymbol{\\theta}}~\\mathbb{E}_{p(t)p(\\mathbf{x}_0)p(\\mathbf{z})}\\left[\\lVert \\mathbf{z}-\\mathbf{z}_{\\boldsymbol{\\theta}}(\\gamma_t \\mathbf{x}_0 + \\sigma_t\\mathbf{z},t)\\rVert^2\\right]. $$\nScore-based Diffusion Model (SDM) predicts the score $\\nabla_{\\mathbf{x}_t}\\log p(\\mathbf{x}_t)$ of the noisy marginal with a score model $\\mathbf{s}_{\\boldsymbol{\\theta}}(\\mathbf{x}_t,t)$. Denoising score matching tells us that this is equivalent to matching the score of the Gaussian forward diffusion process: $$ \\min_{\\boldsymbol{\\theta}}~\\mathbb{E}_{p(t)p(\\mathbf{x}_0)p(\\mathbf{x}_t|\\mathbf{x}_0)}\\left[\\sigma_t^2\\lVert \\nabla_{\\mathbf{x}_t}\\log p(\\mathbf{x}_t|\\mathbf{x}_0) - \\mathbf{s}_{\\boldsymbol{\\theta}}(\\mathbf{x}_t,t) \\rVert^2\\right]. $$\nConnection Between DDPM and SDM In the denoising score matching objective, we can analytically compute the score of the Gaussian forward diffusion process: $$ \\nabla_{\\mathbf{x}_t}\\log p(\\mathbf{x}_t|\\mathbf{x}_0)=-\\frac{\\mathbf{x}_t-\\gamma_t\\mathbf{x}_0}{\\sigma_t^2}=-\\frac{\\mathbf{z}}{\\sigma_t}. $$\nPlugging this into denoising score matching objective, we obtain $$ \\min_{\\boldsymbol{\\theta}}~\\mathbb{E}_{p(t)p(\\mathbf{x}_0)p(\\mathbf{z})}\\left[\\lVert \\mathbf{z}+\\sigma_t\\mathbf{s}_{\\boldsymbol{\\theta}}(\\gamma_t \\mathbf{x}_0 + \\sigma_t\\mathbf{z},t)\\rVert^2\\right]. $$\nThis reveals a connection between the two models: $$ \\mathbf{s}_{\\boldsymbol{\\theta}}(\\mathbf{x}_t,t)=-\\frac{\\mathbf{z}_{\\boldsymbol{\\theta}}(\\mathbf{x}_t,t)}{\\sigma_t}. $$\nTweedie\u0026rsquo;s Formula There is another perhaps less common parameterization of diffusion generative models which is closely related to Tweedie\u0026rsquo;s Formula: $$ \\nabla_{\\mathbf{x}_t}\\log p(\\mathbf{x}_t)=\\frac{\\gamma_t \\mathbb{E}[\\mathbf{x}_0|\\mathbf{x}_t] - \\mathbf{x}_t}{\\sigma_t^2}. $$\nTweedie\u0026rsquo;s Formula tells us: given the Gaussian forward diffusion process, the mean $\\mathbb{E}[\\mathbf{x}_0|\\mathbf{x}_t]$ of the one-step denoising distribution is all we need for constructing the score $\\nabla_{\\mathbf{x}_t}\\log p(\\mathbf{x}_t)$ of the noisy marginal. Therefore, we may construct a new parameterization which predicts $\\mathbb{E}[\\mathbf{x}_0|\\mathbf{x}_t]$ with a parametric model $\\mathbf{m}_{\\boldsymbol{\\theta}}(\\mathbf{x}_t,t)$: $$ \\min_{\\boldsymbol{\\theta}}~\\mathbb{E}_{p(t)p(\\mathbf{x}_0)p(\\mathbf{z})}\\left[\\lVert \\mathbf{x}_0 - \\mathbf{m}_{\\boldsymbol{\\theta}}(\\gamma_t \\mathbf{x}_0 + \\sigma_t\\mathbf{z},t) \\rVert^2\\right]. $$\nTweedie\u0026rsquo;s Formula also reveals a connection between these models: $$ \\mathbf{s}_{\\boldsymbol{\\theta}}(\\mathbf{x}_t,t)=\\frac{\\gamma_t \\mathbf{m}_{\\boldsymbol{\\theta}}(\\mathbf{x}_t,t) - \\mathbf{x}_t}{\\sigma_t^2}\\quad\\text{and}\\quad\\mathbf{z}_{\\boldsymbol{\\theta}}(\\mathbf{x}_t,t)=\\frac{\\mathbf{x}_t - \\gamma_t \\mathbf{m}_{\\boldsymbol{\\theta}}(\\mathbf{x}_t,t)}{\\sigma_t}. $$\nWhat Difference Does It Make? In theory, all these parameterizations are equivalent in the sense that they model the same diffusion generative model (i.e., the backward/denoising process for a given Gaussian forward diffusion process). However, the difficulty of optimization depends on parameterizations quite a lot in practice because they essentially serve as different variance reduction techniques for gradient estimation. It is interesting to note that when the diffusion generative model was first invented, it could not be trained well because of the high variance in the estimated gradient. The authors of DDPM proposed a new parameterization with a set of variance reduction tricks five years later, which was the first time that people had managed to get high quality samples using diffusion generative models.\nAppendix: Proof of Tweedie\u0026rsquo;s Formula Let\u0026rsquo;s now prove Tweedie\u0026rsquo;s Formula in the context of diffusion generative models: $$ \\begin{aligned} \\nabla_{\\mathbf{x}_t}\\log p(\\mathbf{x}_t) \u0026amp;= \\frac{1}{p(\\mathbf{x}_t)} \\nabla_{\\mathbf{x}_t} p(\\mathbf{x}_t) \\\\ \u0026amp;= \\frac{1}{p(\\mathbf{x}_t)} \\nabla_{\\mathbf{x}_t} \\int p(\\mathbf{x}_t|\\mathbf{x}_0)p(\\mathbf{x}_0)d\\mathbf{x}_0 \\\\ \u0026amp;= \\frac{1}{p(\\mathbf{x}_t)} \\int \\nabla_{\\mathbf{x}_t} p(\\mathbf{x}_t|\\mathbf{x}_0)p(\\mathbf{x}_0)d\\mathbf{x}_0 \\\\ \u0026amp;= \\frac{1}{p(\\mathbf{x}_t)} \\int \\frac{\\gamma_t\\mathbf{x}_0-\\mathbf{x}_t}{\\sigma_t^2} p(\\mathbf{x}_t|\\mathbf{x}_0)p(\\mathbf{x}_0)d\\mathbf{x}_0 \\\\ \u0026amp;= \\int \\frac{\\gamma_t\\mathbf{x}_0-\\mathbf{x}_t}{\\sigma_t^2} \\frac{p(\\mathbf{x}_t|\\mathbf{x}_0)p(\\mathbf{x}_0)}{p(\\mathbf{x}_t)}d\\mathbf{x}_0 \\\\ \u0026amp;= \\int \\frac{\\gamma_t\\mathbf{x}_0-\\mathbf{x}_t}{\\sigma_t^2} p(\\mathbf{x}_0|\\mathbf{x}_t)d\\mathbf{x}_0 \\\\ \u0026amp;= \\frac{\\gamma_t \\mathbb{E}[\\mathbf{x}_0|\\mathbf{x}_t] - \\mathbf{x}_t}{\\sigma_t^2}. \\end{aligned} $$\n","date":1703289600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1703289600,"objectID":"a2d83ebb499845a7dedfd145b3116655","permalink":"https://wenlin-chen.github.io/post/diffusion-parameterization/","publishdate":"2023-12-23T00:00:00Z","relpermalink":"/post/diffusion-parameterization/","section":"post","summary":"Introduction Let $p(\\mathbf{x}_0)$ be the data distribution of interest. Consider a Gaussian forward diffusion process in the following form: $$ p(\\mathbf{x}_t|\\mathbf{x}_0)=\\mathcal{N}(\\mathbf{x}_t|\\gamma_t \\mathbf{x}_0,\\sigma_t^2\\mathbf{I}), $$ or, equivalently, $$ \\mathbf{x}_t=\\gamma_t \\mathbf{x}_0 + \\sigma_t\\mathbf{z},\\quad\\mathbf{z}\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I}). $$","tags":null,"title":"Connections Among Different Parameterizations of Diffusion Generative Models","type":"post"},{"authors":["Wen Wu","Wenlin Chen","Chao Zhang","Philip C. Woodland"],"categories":null,"content":"","date":1696032000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696032000,"objectID":"a813e18c87043788c6c22b08f0d565dd","permalink":"https://wenlin-chen.github.io/publication/wu2023has/","publishdate":"2023-09-30T00:00:00Z","relpermalink":"/publication/wu2023has/","section":"publication","summary":"Human annotator simulation (HAS) serves as a cost-effective substitute for human evaluation such as data annotation and system assessment. Human perception and behaviour during human evaluation exhibit inherent variability due to diverse cognitive processes and subjective interpretations, which should be taken into account in modelling to better mimic the way people perceive and interact with the world. This paper introduces a novel meta-learning framework that treats HAS as a zero-shot density estimation problem, which incorporates human variability and allows for the efficient generation of human-like annotations for unlabelled test inputs. Under this framework, we propose two new model classes, conditional integer flows and conditional softmax flows, to account for ordinal and categorical annotations, respectively. The proposed method is evaluated on three real-world human evaluation tasks and shows superior capability and efficiency to predict the aggregated behaviours of human annotators, match the distribution of human annotations, and simulate the inter-annotator disagreements.","tags":[],"title":"It HAS to be Subjective: Human Annotator Simulation via Zero-shot Density Estimation","type":"publication"},{"authors":["Wenlin Chen","Julien Horwood","Juyeon Heo","José Miguel Hernández-Lobato"],"categories":null,"content":"","date":1687824000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1687824000,"objectID":"6039f5f4bbc26f58c353b25a8afbb2f9","permalink":"https://wenlin-chen.github.io/publication/chen2023leveraging/","publishdate":"2023-06-27T00:00:00Z","relpermalink":"/publication/chen2023leveraging/","section":"publication","summary":"This work extends the theory of identifiability in supervised learning by considering the consequences of having access to a distribution of tasks. In such cases, we show that identifiability is achievable even in the case of regression, extending prior work restricted to the single-task classification case. Furthermore, we show that the existence of a task distribution which defines a conditional prior over latent variables reduces the equivalence class for identifiability to permutations and scaling, a much stronger and more useful result. When we further assume a causal structure over these tasks, our approach enables simple maximum marginal likelihood optimization together with downstream applicability to causal representation learning. Empirically, we validate that our model outperforms more general unsupervised models in recovering canonical representations for synthetic and real-world data.","tags":[],"title":"Leveraging Task Structures for Improved Identifiability in Neural Network Representations","type":"publication"},{"authors":["Wenlin Chen","Hong Ge"],"categories":null,"content":"","date":1684972800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684972800,"objectID":"724a54e99e1fb3b3b87a33cffd45322e","permalink":"https://wenlin-chen.github.io/publication/chen2023neural/","publishdate":"2023-05-25T00:00:00Z","relpermalink":"/publication/chen2023neural/","section":"publication","summary":"We examine the characteristic activation values of individual ReLU units in neural networks. We refer to the corresponding set for such characteristic activation values in the input space as the characteristic activation set of a ReLU unit. We draw an explicit connection between the characteristic activation set and learned features in ReLU networks. This connection leads to new insights into why various neural network normalization techniques used in modern deep learning architectures regularize and stabilize SGD optimization. Utilizing these insights, we propose a geometric approach to parameterize ReLU networks for improved feature learning. We empirically verify its usefulness with less carefully chosen initialization schemes and larger learning rates. We report improved optimization stability, faster convergence speed, and better generalization performance.","tags":[],"title":"Neural Characteristic Activation Value Analysis for Improved ReLU Network Feature Learning","type":"publication"},{"authors":["Wenlin Chen","Austin Tripp","José Miguel Hernández-Lobato"],"categories":null,"content":"","date":1682899200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682899200,"objectID":"e7e2dce54685980967029d324635a717","permalink":"https://wenlin-chen.github.io/publication/chen2023meta/","publishdate":"2022-05-05T00:00:00Z","relpermalink":"/publication/chen2023meta/","section":"publication","summary":"We propose Adaptive Deep Kernel Fitting with Implicit Function Theorem (ADKF-IFT), a novel framework for learning deep kernel Gaussian processes (GPs) by interpolating between meta-learning and conventional deep kernel learning. Our approach employs a bilevel optimization objective where we meta-learn generally useful feature representations across tasks, in the sense that task-specific GP models estimated on top of such features achieve the lowest possible predictive loss on average. We solve the resulting nested optimization problem using the implicit function theorem (IFT). We show that our ADKF-IFT framework contains previously proposed Deep Kernel Learning (DKL) and Deep Kernel Transfer (DKT) as special cases. Although ADKF-IFT is a completely general method, we argue that it is especially well-suited for drug discovery problems and demonstrate that it significantly outperforms previous state-of-the-art methods on a variety of real-world few-shot molecular property prediction tasks and out-of-domain molecular property prediction and optimization tasks.","tags":[],"title":"Meta-learning Adaptive Deep Kernel Gaussian Processes for Molecular Property Prediction","type":"publication"},{"authors":["Wenlin Chen","Samuel Horváth","Peter Richtárik"],"categories":null,"content":"","date":1661126400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661126400,"objectID":"eee04c746fd5fbd08cbed0a0667cb0ed","permalink":"https://wenlin-chen.github.io/publication/chen2022optimal/","publishdate":"2022-08-04T00:00:00Z","relpermalink":"/publication/chen2022optimal/","section":"publication","summary":"It is well understood that client-master communication can be a primary bottleneck in federated learning (FL). In this work, we address this issue with a novel client subsampling scheme, where we restrict the number of clients allowed to communicate their updates back to the master node. In each communication round, all participating clients compute their updates, but only the ones with \"important\" updates communicate back to the master. We show that importance can be measured using only the norm of the update and give a formula for optimal client participation. This formula minimizes the distance between the full update, where all clients participate, and our limited update, where the number of participating clients is restricted. In addition, we provide a simple algorithm that approximates the optimal formula for client participation, which allows for secure aggregation and stateless clients, and thus does not compromise client privacy. We show both theoretically and empirically that for Distributed SGD (DSGD) and Federated Averaging (FedAvg), the performance of our approach can be close to full participation and superior to the baseline where participating clients are sampled uniformly. Moreover, our approach is orthogonal to and compatible with existing methods for reducing communication overhead, such as local methods and communication compression methods.","tags":[],"title":"Optimal Client Sampling for Federated Learning","type":"publication"},{"authors":["Austin Tripp","Wenlin Chen","José Miguel Hernández-Lobato"],"categories":null,"content":"","date":1651190400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651190400,"objectID":"7c674ec1dda2935eabce28cc88b5af57","permalink":"https://wenlin-chen.github.io/publication/tripp2022evaluation/","publishdate":"2022-04-29T00:00:00Z","relpermalink":"/publication/tripp2022evaluation/","section":"publication","summary":"De novo drug design has recently received increasing attention from the machine learning community. It is important that the field is aware of the actual goals and challenges of drug design and the roles that de novo molecule design algorithms could play in accelerating the process, so that algorithms can be evaluated in a way that reflects how they would be applied in real drug design scenarios. In this paper, we propose a framework for critically assessing the merits of benchmarks, and argue that most of the existing de novo drug design benchmark functions are either highly unrealistic or depend upon a surrogate model whose performance is not well characterized. In order for the field to achieve its long-term goals, we recommend that poor benchmarks (especially logP and QED) be deprecated in favour of better benchmarks. We hope that our proposed framework can play a part in developing new de novo drug design benchmarks that are more realistic and ideally incorporate the intrinsic goals of drug design.","tags":[],"title":"An Evaluation Framework for the Objective Functions of De Novo Drug Design Benchmarks","type":"publication"},{"authors":["Wenlin Chen"],"categories":null,"content":"","date":1629331200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629331200,"objectID":"12bedca3d469d735925baf247e9638c5","permalink":"https://wenlin-chen.github.io/publication/chen2021causal/","publishdate":"2021-08-19T00:00:00Z","relpermalink":"/publication/chen2021causal/","section":"publication","summary":"In this thesis, we study causal representation learning for latent space optimization, which allows for robust and efficient generation of novel synthetic data with maximal target value.  We assume that the observed data was generated by a few latent factors, some of which are causally related to the target and others of which are spuriously correlated with the target and confounded by an environment variable. Our proposed method consists of three steps, which exploits the structure of the causal graph that describes the assumed underlying data generating process. In the first step, we recover the true data representation (i.e., the latent factors from which the observed data originated). We obtain novel identifiability theory, showing that the true data representation can be recovered up to simple transformations by a generalized version of identifiable variational auto-encoders. In the second step, we identify the causal latent factors of the target, for which we propose a practical causal inference scheme that employs (conditional) independence tests and causal discovery algorithms. Our method does not require having access to the true environment variable, which overcomes a major limitation of existing causal representation learning approaches in the literature. In the final step, we query latent points that correspond to data points with high target values by intervening upon the causal latent factors using standard latent space optimization techniques. We empirically evaluate and thoroughly analyze our method on three different tasks, including a chemical design task. We show that our method can successfully recover the true data representation in the finite data regime and correctly identify the causal latent factors of the target, which results in state-of-the-art performance for black-box optimization.","tags":[],"title":"Causal Representation Learning for Latent Space Optimization","type":"publication"},{"authors":["Andrew Webb","Charles Reynolds","Wenlin Chen","Henry Reeve","Dan Iliescu","Mikel Luján","Gavin Brown"],"categories":null,"content":"","date":1600041600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600041600,"objectID":"73540bab56f2b0d108a710976f7b0dcb","permalink":"https://wenlin-chen.github.io/publication/webb2020ensemble/","publishdate":"2020-09-14T00:00:00Z","relpermalink":"/publication/webb2020ensemble/","section":"publication","summary":"End-to-End training (E2E) is becoming more and more popular to train complex Deep Network architectures. An interesting question is whether this trend will continue—are there any clear failure cases for E2E training? We study this question in depth, for the specific case of E2E training an ensemble of networks. Our strategy is to blend the gradient smoothly in between two extremes: from independent training of the networks, up to to full E2E training. We find clear failure cases, where overparameterized models cannot be trained E2E. A surprising result is that the optimum can sometimes lie in between the two, neither an ensemble or an E2E system. The work also uncovers links to Dropout, and raises questions around the nature of ensemble diversity and multi-branch networks.","tags":[],"title":"To Ensemble or Not Ensemble: When Does End-to-End Training Fail?","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://wenlin-chen.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]